    @Override
    public synchronized AlarmSyncResults handleAlarmSnapshot(List<OnmsAlarm> alarms, long systemMillisBeforeSnapshot) {
        if (!isReady()) {
            LOG.debug("Alarm store is not ready yet. Skipping synchronization.");
            return null;
        }

        LOG.debug("Performing alarm synchronization with ktable.");
        final AlarmSyncResults results;
        try {
            // Retrieve the map of alarms by reduction key from the ktable
            final Map<String, OpennmsModelProtos.Alarm> alarmsInKtableByReductionKey = getAlarms();

            final Set<String> reductionKeysInKtable = alarmsInKtableByReductionKey.keySet();

            // Use the given alarms and apply the filter (if any) to these
            // This represents the set of alarms that should be in the ktable at the given timestamp
            final List<OnmsAlarm> alarmsInDb = alarms.stream()
                    .filter(kafkaProducer::shouldForwardAlarm)
                    .collect(Collectors.toList());

            final Map<String, OnmsAlarm> alarmsInDbByReductionKey = alarmsInDb.stream()
                    .collect(Collectors.toMap(OnmsAlarm::getReductionKey, a -> a));
            final Set<String> reductionKeysInDb = alarmsInDbByReductionKey.keySet();

            // Grab a reference to the state tracker
            final AlarmCallbackStateTracker stateTracker = kafkaProducer.getAlarmCallbackStateTracker();
            // Remove entries from state tracking that happened before the snapshot
            stateTracker.expireEntriesBefore(systemMillisBeforeSnapshot);

            // Push deletes for keys that are in the ktable, but not in the database
            final Set<String> reductionKeysNotInDb = Sets.difference(reductionKeysInKtable, reductionKeysInDb).stream()
                    // Only remove it if the alarm we have dates before the snapshot
                    .filter(reductionKey -> !stateTracker.wasAlarmWithReductionKeyUpdatedOnOrAfter(reductionKey, systemMillisBeforeSnapshot))
                    .collect(Collectors.toSet());
            reductionKeysNotInDb.forEach(rkey -> kafkaProducer.handleDeletedAlarm((int)alarmsInKtableByReductionKey.get(rkey).getId(), rkey));

            // Push new entries for keys that are in the database, but not in the ktable
            final Set<String> reductionKeysNotInKtable = Sets.difference(reductionKeysInDb, reductionKeysInKtable).stream()
                    // Unless we've deleted the alarm after the snapshot time
                    .filter(reductionKey -> !stateTracker.wasAlarmWithReductionKeyDeletedOnOrAfter(reductionKey, systemMillisBeforeSnapshot))
                    .collect(Collectors.toSet());
            reductionKeysNotInKtable.forEach(rkey -> kafkaProducer.handleNewOrUpdatedAlarm(alarmsInDbByReductionKey.get(rkey)));

            // Handle Updates
            final Set<String> reductionKeysUpdated = new LinkedHashSet<>();
            final Set<String> commonReductionKeys = Sets.intersection(reductionKeysInKtable, reductionKeysInDb);
            commonReductionKeys.forEach(rkey -> {
                // Don't bother updating the alarm if the one we we have is more recent than the snapshot
                if (stateTracker.wasAlarmWithReductionKeyUpdatedOnOrAfter(rkey, systemMillisBeforeSnapshot)) {
                    return;
                }

                final OnmsAlarm dbAlarm = alarmsInDbByReductionKey.get(rkey);
                final OpennmsModelProtos.Alarm.Builder mappedDbAlarm = protobufMapper.toAlarm(dbAlarm);
                final OpennmsModelProtos.Alarm alarmFromKtable = alarmsInKtableByReductionKey.get(rkey);
                final OpennmsModelProtos.Alarm.Builder alarmBuilderFromKtable =
                        alarmsInKtableByReductionKey.get(rkey).toBuilder();

                if ((suppressIncrementalAlarms && !alarmEqualityChecker.equalsExcludingOnBoth(mappedDbAlarm,
                        alarmBuilderFromKtable)) || (!suppressIncrementalAlarms && !Objects.equals(mappedDbAlarm.build(),
                        alarmFromKtable))) {
                    kafkaProducer.handleNewOrUpdatedAlarm(dbAlarm);
                    reductionKeysUpdated.add(rkey);
                }
            });

            results = new AlarmSyncResults(alarmsInKtableByReductionKey, alarmsInDb, alarmsInDbByReductionKey,
                    reductionKeysNotInKtable, reductionKeysNotInDb, reductionKeysUpdated);
        } catch (Exception e) {
            LOG.error("An error occurred while performing alarm synchronization with the ktable. Will try again on next callback.", e);
            return null;
        }

        if (LOG.isDebugEnabled()) {
            LOG.debug("Done performing alarm synchronization with the ktable for {} alarms. Executed {} updates.",
                    results.getAlarmsInDb().size(),
                    results.getReductionKeysAdded().size()
                            + results.getReductionKeysDeleted().size()
                            + results.getReductionKeysUpdated().size());
            LOG.debug("Reduction keys added to ktable: {}", results.getReductionKeysAdded());
            LOG.debug("Reduction keys deleted from the ktable: {}", results.getReductionKeysDeleted());
            LOG.debug("Reduction keys updated in the ktable: {}", results.getReductionKeysUpdated());
        }

        return results;
    }

