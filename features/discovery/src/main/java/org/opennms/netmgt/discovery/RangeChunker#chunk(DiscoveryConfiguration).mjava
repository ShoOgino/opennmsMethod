    public Map<String, List<DiscoveryJob>> chunk(final DiscoveryConfiguration config) {

        final int chunkSize = config.getChunkSize().orElse(DiscoveryConfigFactory.DEFAULT_CHUNK_SIZE);
        final double packetsPerSecond = config.getPacketsPerSecond().orElse(DiscoveryConfigFactory.DEFAULT_PACKETS_PER_SECOND);

        // If the foreign source for the discovery config is not set than use 
        // a value of null so that non-requisitioned nodes are created.
        //
        // TODO: Use the "default" foreign source instead so that we can move
        // away from using non-requisitioned nodes.
        //
        final String foreignSourceFromConfig = config.getForeignSource().isPresent()? config.getForeignSource().get().trim() : null;

        // If the monitoring location for the discovery config is not set than use 
        // the default localhost location
        final String locationFromConfig = config.getLocation().map(l -> {
            final String trimmed = l.trim();
            if ("".equals(trimmed)) {
                return null;
            }
            return trimmed;
        }).orElse(MonitoringLocationDao.DEFAULT_MONITORING_LOCATION_ID);

        final DiscoveryConfigFactory configFactory = new DiscoveryConfigFactory(config);

        final AtomicReference<IPPollRange> previousRange = new AtomicReference<>();

        return StreamSupport.stream(configFactory.getConfiguredAddresses().spliterator(), false)
            .filter(address -> {
                // If there is no IP address filter set or the filter matches
                return ipAddressFilter.matches(address.getLocation(), address.getAddress());
            })
            // TODO: We could optimize this further by not unrolling IPPollRanges into individual
            // IPPollAddresses during the mapping.
            .map(address -> {
                // Create a singleton IPPollRange
                return new IPPollRange(
                    // Make sure that foreignSource is not null so that we can partition on the value
                    address.getForeignSource() == null ? foreignSourceFromConfig : address.getForeignSource(),
                    // Make sure that location is not null so that we can partition on the value
                    address.getLocation() == null ? locationFromConfig : address.getLocation(),
                    address.getAddress(),
                    address.getAddress(),
                    address.getTimeout(),
                    address.getRetries()
                );
            })
            .collect(Collectors.groupingBy(range -> {
                // Create a Map<ForeignSourceLocationKey,List<IPPollRange>>
                return new ForeignSourceLocationKey(
                    // Make sure that foreignSource is not null so that we can partition on the value
                    range.getForeignSource() == null ? foreignSourceFromConfig : range.getForeignSource(),
                    // Make sure that location is not null so that we can partition on the value
                    range.getLocation() == null ? locationFromConfig : range.getLocation()
                );
            }, LinkedHashMap::new, Collectors.toList()))
            .entrySet().stream()
            // Flat map one list of IPPollRanges to many chunked DiscoveryJobs
            .flatMap(entry -> {
                // Partition the list of address values
                return Lists.partition(entry.getValue(), chunkSize).stream()
                    // Map each partition value to a separate DiscoveryJob
                    .map(ranges -> {
                        DiscoveryJob retval = new DiscoveryJob(
                            ranges.stream()
                                .map(address -> {
                                    // If this address is consecutive with the previous range,
                                    // then just extend the range to cover this address too
                                    if (isConsecutive(previousRange.get(), address)) {
                                        previousRange.get().getAddressRange().incrementEnd();
                                        return null;
                                    }
                                    previousRange.set(address);
                                    return address;
                                })
                                // Filter out all of the consecutive values that we nulled out
                                .filter(Objects::nonNull)
                                // Convert back into a list of ranges
                                .collect(Collectors.toList()),
                            entry.getKey().getForeignSource(),
                            entry.getKey().getLocation(),
                            packetsPerSecond,
                                config);
                        // Reset the previousRange value
                        previousRange.set(null);
                        return retval;
                    })
                    // Collect the DiscoveryJobs
                    .collect(Collectors.toList()).stream();
            })
            .collect(Collectors.groupingBy(DiscoveryJob::getLocation,
                    LinkedHashMap::new, Collectors.toList()));
    }

