    public Map<String, List<DiscoveryJob>> chunk(final DiscoveryConfiguration config) {

        final int chunkSize = (config.getChunkSize() != null && config.getChunkSize() > 0) ? config.getChunkSize() : DiscoveryConfigFactory.DEFAULT_CHUNK_SIZE;
        final double packetsPerSecond = (config.getPacketsPerSecond() != null && config.getPacketsPerSecond() > 0.0) ? config.getPacketsPerSecond() : DiscoveryConfigFactory.DEFAULT_PACKETS_PER_SECOND;

        // If the foreign source for the discovery config is not set than use 
        // a value of null so that non-requisitioned nodes are created.
        //
        // TODO: Use the "default" foreign source instead so that we can move
        // away from using non-requisitioned nodes.
        //
        final String foreignSourceFromConfig = (config.getForeignSource() == null || "".equals(config.getForeignSource().trim())) ? null : config.getForeignSource().trim();

        // If the monitoring location for the discovery config is not set than use 
        // the default localhost location
        final String locationFromConfig = (config.getLocation() == null || "".equals(config.getLocation().trim())) ? MonitoringLocationDao.DEFAULT_MONITORING_LOCATION_ID : config.getLocation().trim();

        final DiscoveryConfigFactory configFactory = new DiscoveryConfigFactory(config);

        final AtomicReference<IPPollRange> previousRange = new AtomicReference<>();

        return StreamSupport.stream(configFactory.getConfiguredAddresses().spliterator(), false)
            .filter(address -> {
                // If there is no IP address filter set or the filter matches
                return ipAddressFilter.matches(address.getLocation(), address.getAddress());
            })
            // TODO: We could optimize this further by not unrolling IPPollRanges into individual
            // IPPollAddresses during the mapping.
            .map(address -> {
                // Create a singleton IPPollRange
                return new IPPollRange(
                    // Make sure that foreignSource is not null so that we can partition on the value
                    address.getForeignSource() == null ? foreignSourceFromConfig : address.getForeignSource(),
                    // Make sure that location is not null so that we can partition on the value
                    address.getLocation() == null ? locationFromConfig : address.getLocation(),
                    address.getAddress(),
                    address.getAddress(),
                    address.getTimeout(),
                    address.getRetries()
                );
            })
            .collect(Collectors.groupingBy(range -> {
                // Create a Map<ForeignSourceLocationKey,List<IPPollRange>>
                return new ForeignSourceLocationKey(
                    // Make sure that foreignSource is not null so that we can partition on the value
                    range.getForeignSource() == null ? foreignSourceFromConfig : range.getForeignSource(),
                    // Make sure that location is not null so that we can partition on the value
                    range.getLocation() == null ? locationFromConfig : range.getLocation()
                );
            }, LinkedHashMap::new, Collectors.toList()))
            .entrySet().stream()
            // Flat map one list of IPPollRanges to many chunked DiscoveryJobs
            .flatMap(entry -> {
                // Partition the list of address values
                return Lists.partition(entry.getValue(), chunkSize).stream()
                    // Map each partition value to a separate DiscoveryJob
                    .map(ranges -> {
                        DiscoveryJob retval = new DiscoveryJob(
                            ranges.stream()
                                .map(address -> {
                                    // If this address is consecutive with the previous range,
                                    // then just extend the range to cover this address too
                                    if (isConsecutive(previousRange.get(), address)) {
                                        previousRange.get().getAddressRange().incrementEnd();
                                        return null;
                                    }
                                    previousRange.set(address);
                                    return address;
                                })
                                // Filter out all of the consecutive values that we nulled out
                                .filter(Objects::nonNull)
                                // Convert back into a list of ranges
                                .collect(Collectors.toList()),
                            entry.getKey().getForeignSource(),
                            entry.getKey().getLocation(),
                            packetsPerSecond
                        );
                        // Reset the previousRange value
                        previousRange.set(null);
                        return retval;
                    })
                    // Collect the DiscoveryJobs
                    .collect(Collectors.toList()).stream();
            })
            .collect(Collectors.groupingBy(job -> job.getLocation(),
                    LinkedHashMap::new, Collectors.toList()));
    }

