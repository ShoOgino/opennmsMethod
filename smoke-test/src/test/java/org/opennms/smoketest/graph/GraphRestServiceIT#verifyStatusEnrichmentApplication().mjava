    @Test
    public void verifyStatusEnrichmentApplication() {
        final HibernateDaoFactory daoFactory = stack.postgres().getDaoFactory();
        final ApplicationDaoHibernate applicationDao = daoFactory.getDao(ApplicationDaoHibernate.class);
        final MonitoredServiceDao monitoredServiceDao = daoFactory.getDao(MonitoredServiceDaoHibernate.class);
        final PlatformTransactionManager transactionManager = new HibernateTransactionManager(applicationDao.getSessionFactory());
        final TransactionTemplate transactionTemplate = new TransactionTemplate(transactionManager);

        // Clean up
        applicationDao.findAll().forEach(applicationDao::delete);

        // Set up test data
        createRequisition();
        final OnmsApplication tmpApplication = transactionTemplate.execute(transactionStatus -> {
            final OnmsApplication theApplication = new OnmsApplication();
            theApplication.setName("OpenNMS Application");
            monitoredServiceDao.findAllServices().stream()
                    .filter(ms -> ms.getIpAddress().toString().contains("127.0.0.1"))
                    .forEach(service -> service.addApplication(theApplication));
            applicationDao.save(theApplication);
            return theApplication;
        });

        // Force fully initialized to prevent LazyLoad-Exceptions
        final OnmsApplication application = transactionTemplate.execute(status -> {
            final OnmsApplication initializedApplication = applicationDao.get(tmpApplication.getId());
            initializedApplication.getMonitoredServices().stream().forEach(OnmsMonitoredService::getNodeId);
            return initializedApplication;
        });

        // Force application provider to reload (otherwise we have to wait until cache is invalidated)
        karafShell.runCommand("opennms-graph:force-reload --container application");

        // Fetch data nothing down
        final JSONObject query = new JSONObject()
                .put("semanticZoomLevel", 1)
                .put("verticesInFocus", Lists.newArrayList(String.format("Application:%s", application.getId())));
        given().log().ifValidationFails()
                .body(query.toString())
                .contentType(ContentType.JSON)
                .post("{container_id}/{namespace}", "application", "application")
                .then()
                .log().ifValidationFails()
                .statusCode(200)
                .contentType(ContentType.JSON)
                .content("vertices", Matchers.hasSize(3))
                .content("vertices[0].status.severity", Matchers.is("Normal"))
                .content("vertices[1].status.severity", Matchers.is("Normal"))
                .content("vertices[2].status.severity", Matchers.is("Normal"))
                .content("vertices[0].status.count", Matchers.is(0))
                .content("vertices[1].status.count", Matchers.is(0))
                .content("vertices[2].status.count", Matchers.is(0));

        // Prepare simulated outages
        final List<OnmsMonitoredService> services = Lists.newArrayList(application.getMonitoredServices());
        final int nodeId1 = services.get(0).getNodeId();
        final int nodeId2 = services.get(1).getNodeId();
        final Event nodeLostServiceEvent = new EventBuilder(EventConstants.NODE_LOST_SERVICE_EVENT_UEI, getClass().getSimpleName())
                .setNodeid(nodeId1)
                .setInterface(InetAddressUtils.getInetAddress("127.0.0.1"))
                .setService("ICMP")
                .getEvent();
        final Event nodeDownEvent = new EventBuilder(EventConstants.NODE_DOWN_EVENT_UEI, getClass().getSimpleName())
                .setNodeid(nodeId2)
                .getEvent();

        // Take service down, reload graph and verify
        restClient.sendEvent(nodeLostServiceEvent);
        karafShell.runCommand("opennms-graph:force-reload --container application");
        given().log().ifValidationFails()
                .body(query.toString())
                .contentType(ContentType.JSON)
                .post("{container_id}/{namespace}", "application", "application")
                .then()
                .log().ifValidationFails()
                .statusCode(200)
                .contentType(ContentType.JSON)
                .content("vertices", Matchers.hasSize(3))
                .content("vertices[0].status.severity", Matchers.is("Minor"))
                .content("vertices[1].status.severity", Matchers.is("Minor"))
                .content("vertices[2].status.severity", Matchers.is("Normal"))
                .content("vertices[0].status.count", Matchers.is(1))
                .content("vertices[1].status.count", Matchers.is(1))
                .content("vertices[2].status.count", Matchers.is(0));

        // Take node down, reload graph and verify
        restClient.sendEvent(nodeDownEvent);
        karafShell.runCommand("opennms-graph:force-reload --container application");
        given().log().ifValidationFails()
                .body(query.toString())
                .contentType(ContentType.JSON)
                .post("{container_id}/{namespace}", "application", "application")
                .then()
                .log().ifValidationFails()
                .statusCode(200)
                .contentType(ContentType.JSON)
                .content("vertices", Matchers.hasSize(3))
                .content("vertices[0].status.severity", Matchers.is("Major"))
                .content("vertices[1].status.severity", Matchers.is("Minor"))
                .content("vertices[2].status.severity", Matchers.is("Major"))
                .content("vertices[0].status.count", Matchers.is(1))
                .content("vertices[1].status.count", Matchers.is(1))
                .content("vertices[2].status.count", Matchers.is(1));

        // Finally clean up
        applicationDao.delete(application);
    }

